# MarketingAnalysis_Aribnb-Listings-Performance

## üìå Project Purpose

## üìä Dataset Description
- Source: [Airbnb NYC Listings](https://insideairbnb.com/get-the-data/)
- The original dataset includes 79 columns and 36111 rows. After cleaning, we have 53 columns for analysis
  
- Data Dictionary: [Click here to see the whole column definition](https://github.com/Andreapan131/MarketingAnalysis_Aribnb-Listings-Performance/blob/main/Airbnb%20Open%20Data%20Dictionary.xlsx)
  - **Host & Listing Characteristics**  
    e.g. host_is_superhost, host_response_time, host_years_active, host_listings_count, accommodates, bedrooms, bathrooms, beds, amenities, room_type, latitude, longitude, neighbourhood...
  - **Pricing & Performance Metrics**  
    e.g. price, minimum_nights, maximum_nights, instant_bookable, estimated_revenue_l365d, estimated_occupancy_l365d
  - **Reviews & Demand Signals**  
    e.g. review_scores, number_of_reviews, reviews_per_month, number_of_reviews_ltm, number_of_reviews_l30d, *review_cluster

## üè∑ Methodology
### 1Ô∏è‚É£ Data Preprocessing
- Data Cleaning
  - Dropped columns and rows
  - Removed outliers and missing values
  - Transformed data type and format

### 2Ô∏è‚É£ K-means Clustering
- Applied K-means clustering using review-related variables
- Used the Elbow Method to determine the optimal number of clusters (k = 3)
- Merged cluster labels into the original dataset

### 3Ô∏è‚É£ Statistical Testing (ANOVA)
One-way ANOVA was used to evaluate if the review-based clusters represent meaningful and distinct group.
- Tested whether customer engagement (measured by review volume) differs significantly across clusters
- Examined whether pricing differs across clusters to ensure that observed performance differences are not simply driven by price

### 4Ô∏è‚É£ Regression Analysis
Because cluster patterns alone cannot establish a review‚Äìrevenue relationship, linear regression was used as a formal modeling approach.
- Estimated revenue over the past 365 days was used as the dependent variable
- Overall review score was specified as the key independent variable
- Control variable were included to hold other factors constant

### 5Ô∏è‚É£ Data Visualization
- Cluster-level comparisons and distributions
- Regression relationships between review quality and revenue
- Neighborhood-level performance patterns

## üîç Key Findings & Insights
- 1Ô∏è‚É£ **Review Quality Differs Meaningfully Across Listings**
  - Low-quality listings underperform most on perceived value and accuracy
  - Cleanliness and communication decline consistently with lower review quality
  
- 2Ô∏è‚É£ **Host Experience and Review Volume**
  - High rating clusters are associated with more experienced hosts
  - Listings in higher-quality clusters receive more reviews
    
- 3Ô∏è‚É£ **Performance Gaps Vary by Neighborhood**
  - Manhattan has the highest propotion of low rating listings and the smallest share of top-rated listings
  - Staten Island shows the opposite pattern, with the strongest concentration of high-quality listings
  
- 4Ô∏è‚É£ **Demand Follows Quality, Not Price**
  - Prices do not differ meaningfully across review-based clusters
  - Review quality has a statistically significant positive association with revenue after controlling for price, location, and listing features

## üìä Visualizations


## üöÄ Business & Social Implications
- Shift from supply-driven growth to quality-driven growth
- Higher review volume strengthens platform reliability by increasing transparency and guest confidence
- Pricing cannot compensate for poor quality and will not drive occupancy increases
- Target quality investments geographically for maximum impact
  
## üìÇ Repository Files

